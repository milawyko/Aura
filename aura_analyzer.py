import cv2
import numpy as np
import json
from datetime import datetime
import mediapipe as mp
from transformers import pipeline
import torch
import hashlib
import time
import os
import glob

class AuraHealthAnalyzer:
    def __init__(self, use_huggingface=True):
        self.face_detector = mp.solutions.face_detection.FaceDetection(
            model_selection=1, min_detection_confidence=0.7
        )
        
        self.face_mesh = mp.solutions.face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.7
        )
        
        self.celebrity_database = self._initialize_celebrity_database()
        self.analysis_history = []
        self.use_huggingface = use_huggingface
        
        if use_huggingface:
            self._initialize_huggingface_models()

    def _initialize_huggingface_models(self):
        """Initialize Hugging Face models for emotion detection"""
        try:
            self.emotion_detector = pipeline(
                "image-classification",
                model="trpakov/vit-face-expression",
                device=0 if torch.cuda.is_available() else -1
            )
            print("‚úÖ Hugging Face models loaded successfully")
        except Exception as e:
            print(f"‚ùå Could not load Hugging Face models: {e}")
            self.use_huggingface = False

    def _initialize_celebrity_database(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–µ–π –∏–∑ –ø–∞–ø–∫–∏ celebrities"""
        celeb_folder = "celebrities"
        
        if not os.path.exists(celeb_folder):
            print("‚ùå –ü–∞–ø–∫–∞ celebrities –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –°–æ–∑–¥–∞–π –ø–∞–ø–∫—É —Å —Ñ–æ—Ç–æ –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–µ–π")
            return {}
        
        image_files = []
        for ext in ["*.jpg", "*.png", "*.jpeg", "*.JPG", "*.PNG", "*.JPEG"]:
            image_files.extend(glob.glob(os.path.join(celeb_folder, ext)))
        
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(image_files)} —Ñ–æ—Ç–æ –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–µ–π")
        
        celebrity_database = {}
        
        for image_path in image_files:
            try:
                if not os.path.exists(image_path) or os.path.getsize(image_path) == 0:
                    continue
                
                filename = os.path.basename(image_path)
                celeb_name = os.path.splitext(filename)[0].replace('_', ' ').title()
                
                print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {celeb_name}")
                
                celeb_metrics = self._analyze_celebrity_photo(image_path)
                if celeb_metrics:
                    celebrity_database[celeb_name] = {
                        "name": celeb_name,
                        "image_path": image_path,
                        "metrics": celeb_metrics
                    }
                    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞: {celeb_name}")
                else:
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {celeb_name}")
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ {os.path.basename(image_path)}: {str(e)}")
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(celebrity_database)} –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–µ–π")
        return celebrity_database

    def _analyze_celebrity_photo(self, image_path):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–æ—Ç–æ –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏"""
        try:
            img = cv2.imread(image_path)
            if img is None:
                return None
            
            # –ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            img = cv2.resize(img, (500, 500))
            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞
            results = self.face_detector.process(rgb_img)
            if not results.detections:
                return None
            
            # –û–±—Ä–µ–∑–∞–µ–º –ª–∏—Ü–æ
            detection = results.detections[0]
            bbox = detection.location_data.relative_bounding_box
            h, w = img.shape[:2]
            
            x = int(bbox.xmin * w)
            y = int(bbox.ymin * h)
            face_w = int(bbox.width * w)
            face_h = int(bbox.height * h)
            
            margin = 0.1
            x = max(0, int(x - face_w * margin))
            y = max(0, int(y - face_h * margin))
            face_w = min(w - x, int(face_w * (1 + 2 * margin)))
            face_h = min(h - y, int(face_h * (1 + 2 * margin)))
            
            face_img = img[y:y+face_h, x:x+face_w]
            
            if face_img.size == 0:
                return None
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–∂–∏
            skin_quality = self._analyze_skin_quality(face_img)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–≤–µ–∂–µ—Å—Ç—å –≥–ª–∞–∑
            eye_freshness = self._analyze_eye_freshness(face_img)
            
            return {
                "skin_evenness": skin_quality["evenness"],
                "skin_smoothness": skin_quality["smoothness"], 
                "skin_cleanliness": skin_quality["cleanliness"],
                "eye_freshness": eye_freshness,
                "energy_level": 0.8 + (eye_freshness * 0.2)
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {image_path}: {str(e)}")
            return None

    def analyze_3d_scan_from_bytes(self, front_bytes: bytes, left_bytes: bytes, right_bytes: bytes, user_id: str = "default"):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ 3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –±—ç–∫–µ–Ω–¥–∞"""
        start_time = time.time()
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ bytes
            front_data = self._analyze_frontal_from_bytes(front_bytes)
            left_data = self._analyze_profile_from_bytes(left_bytes)
            right_data = self._analyze_profile_from_bytes(right_bytes)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ—Ä—ã
            scores = self._calculate_scores(front_data, left_data, right_data)
            metrics = self._compile_metrics(front_data)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = self._generate_recommendations(scores, metrics)
            celebrity_match = self.get_celebrity_match({"metrics": metrics})
            
            processing_time = round(time.time() - start_time, 2)
            
            result = {
                'scan_id': self._generate_scan_id(),
                'user_id': user_id,
                'timestamp': datetime.now().isoformat(),
                'scores': scores,
                'metrics': metrics,
                'recommendations': recommendations,
                'celebrity_match': celebrity_match,
                'processing_time': processing_time
            }
            
            self.analysis_history.append(result)
            return result
            
        except Exception as e:
            return {"error": f"Analysis error: {str(e)}"}

    def _analyze_frontal_from_bytes(self, image_bytes: bytes):
        """–ê–Ω–∞–ª–∏–∑ —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ —Ñ–æ—Ç–æ –∏–∑ bytes"""
        processed_img = self._preprocess_image_from_bytes(image_bytes)
        rgb_img = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)
        
        mesh_results = self.face_mesh.process(rgb_img)
        emotion_analysis = self._analyze_emotions(rgb_img) if self.use_huggingface else {}
        
        return {
            'energy': self._analyze_energy(processed_img, mesh_results),
            'skin': self._analyze_skin_quality(processed_img),
            'stress': self._analyze_stress(processed_img, mesh_results, emotion_analysis)
        }

    def _analyze_profile_from_bytes(self, image_bytes: bytes):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ñ–∏–ª—å–Ω–æ–≥–æ —Ñ–æ—Ç–æ –∏–∑ bytes"""
        try:
            processed_img = self._preprocess_image_from_bytes(image_bytes)
            return {
                'puffiness': 0.3,
                'symmetry': 0.8
            }
        except:
            return {}

    def _preprocess_image_from_bytes(self, image_bytes: bytes):
        """–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ bytes"""
        nparr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img is None:
            raise ValueError("Cannot decode image from bytes")
        
        img = self._normalize_lighting(img)
        img = self._white_balance(img)
        img = self._denoise_image(img)
        face_img = self._detect_face_modern(img)
        
        return face_img

    def _normalize_lighting(self, img):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è"""
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l_normalized = clahe.apply(l)
        lab_normalized = cv2.merge([l_normalized, a, b])
        return cv2.cvtColor(lab_normalized, cv2.COLOR_LAB2BGR)

    def _white_balance(self, img):
        """–ö–æ—Ä—Ä–µ–∫—Ü–∏—è –±–∞–ª–∞–Ω—Å–∞ –±–µ–ª–æ–≥–æ"""
        result = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        avg_a = np.average(result[:, :, 1])
        avg_b = np.average(result[:, :, 2])
        result[:, :, 1] = result[:, :, 1] - ((avg_a - 128) * (result[:, :, 0] / 255.0) * 1.1)
        result[:, :, 2] = result[:, :, 2] - ((avg_b - 128) * (result[:, :, 0] / 255.0) * 1.1)
        return cv2.cvtColor(result, cv2.COLOR_LAB2BGR)

    def _denoise_image(self, img):
        """–£–¥–∞–ª–µ–Ω–∏–µ —à—É–º–æ–≤"""
        return cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)

    def _detect_face_modern(self, img):
        """–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞ —Å MediaPipe"""
        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.face_detector.process(rgb_img)
        
        if not results.detections:
            raise ValueError("No face detected")
        
        detection = results.detections[0]
        bbox = detection.location_data.relative_bounding_box
        h, w = img.shape[:2]
        
        x = int(bbox.xmin * w)
        y = int(bbox.ymin * h)
        face_w = int(bbox.width * w)
        face_h = int(bbox.height * h)
        
        margin = 0.1
        x = max(0, int(x - face_w * margin))
        y = max(0, int(y - face_h * margin))
        face_w = min(w - x, int(face_w * (1 + 2 * margin)))
        face_h = min(h - y, int(face_h * (1 + 2 * margin)))
        
        return img[y:y+face_h, x:x+face_w]

    def _analyze_energy(self, face_img, mesh_results):
        """–ê–Ω–∞–ª–∏–∑ —ç–Ω–µ—Ä–≥–∏–∏ –∏ —É—Å—Ç–∞–ª–æ—Å—Ç–∏"""
        dark_circle_score = self._analyze_dark_circles(face_img)
        eye_freshness = self._analyze_eye_freshness(face_img)
        
        energy_score = 100 - (dark_circle_score * 40 + (1 - eye_freshness) * 40)
        
        return {
            'score': max(0, min(energy_score, 100)),
            'dark_circles': dark_circle_score,
            'eye_freshness': eye_freshness
        }

    def _analyze_dark_circles(self, face_img):
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–º–Ω—ã—Ö –∫—Ä—É–≥–æ–≤ –ø–æ–¥ –≥–ª–∞–∑–∞–º–∏"""
        eye_regions = self._extract_eye_regions(face_img)
        
        if len(eye_regions) < 2:
            return 0.5
        
        dark_scores = []
        for eye_region in eye_regions:
            h, w = eye_region.shape[:2]
            under_eye = eye_region[int(h*0.7):h, :]
            
            if under_eye.size == 0:
                continue
            
            hsv = cv2.cvtColor(under_eye, cv2.COLOR_RGB2HSV)
            
            lower_blue = np.array([100, 40, 20])
            upper_blue = np.array([140, 255, 150])
            blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)
            
            lower_brown = np.array([0, 40, 20])
            upper_brown = np.array([20, 255, 150])
            brown_mask = cv2.inRange(hsv, lower_brown, upper_brown)
            
            combined_mask = cv2.bitwise_or(blue_mask, brown_mask)
            dark_ratio = np.sum(combined_mask > 0) / combined_mask.size
            
            dark_scores.append(min(dark_ratio * 2, 1.0))
        
        return np.mean(dark_scores) if dark_scores else 0.0

    def _extract_eye_regions(self, face_img):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–µ–π –≥–ª–∞–∑ –ø–æ landmarks"""
        rgb_face = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
        mesh_results = self.face_mesh.process(rgb_face)
        
        if not mesh_results.multi_face_landmarks:
            return []
        
        eye_regions = []
        landmarks = mesh_results.multi_face_landmarks[0].landmark
        
        left_eye_indices = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
        right_eye_indices = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
        
        for eye_indices in [left_eye_indices, right_eye_indices]:
            points = []
            for idx in eye_indices:
                x = int(landmarks[idx].x * face_img.shape[1])
                y = int(landmarks[idx].y * face_img.shape[0])
                points.append([x, y])
            
            if points:
                x_coords = [p[0] for p in points]
                y_coords = [p[1] for p in points]
                x_min, x_max = min(x_coords), max(x_coords)
                y_min, y_max = min(y_coords), max(y_coords)
                
                padding = 5
                x_min = max(0, x_min - padding)
                y_min = max(0, y_min - padding)
                x_max = min(face_img.shape[1], x_max + padding)
                y_max = min(face_img.shape[0], y_max + padding)
                
                eye_region = face_img[y_min:y_max, x_min:x_max]
                if eye_region.size > 0:
                    eye_regions.append(eye_region)
        
        return eye_regions

    def _analyze_eye_freshness(self, face_img):
        """–ê–Ω–∞–ª–∏–∑ —Å–≤–µ–∂–µ—Å—Ç–∏ –≥–ª–∞–∑"""
        eye_regions = self._extract_eye_regions(face_img)
        
        if len(eye_regions) < 2:
            return 0.5
        
        freshness_scores = []
        for eye_region in eye_regions:
            h, w = eye_region.shape[:2]
            eye_white = eye_region[int(h*0.2):int(h*0.6), int(w*0.2):int(w*0.8)]
            
            if eye_white.size == 0:
                continue
            
            brightness = np.mean(cv2.cvtColor(eye_white, cv2.COLOR_RGB2GRAY))
            freshness_scores.append(brightness / 255.0)
        
        return np.mean(freshness_scores) if freshness_scores else 0.5

    def _analyze_skin_quality(self, face_img):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–∂–∏"""
        face_resized = cv2.resize(face_img, (200, 200))
        
        hsv = cv2.cvtColor(face_resized, cv2.COLOR_RGB2HSV)
        color_evenness = max(0, 1 - np.std(hsv[:,:,0]) / 30)
        
        gray = cv2.cvtColor(face_resized, cv2.COLOR_RGB2GRAY)
        smoothness = max(0, 1 - cv2.Laplacian(gray, cv2.CV_64F).var() / 500)
        
        cleanliness = self._analyze_skin_cleanliness(face_resized)
        
        skin_score = (color_evenness * 0.4 + smoothness * 0.4 + cleanliness * 0.2) * 100
        
        return {
            'score': max(0, min(skin_score, 100)),
            'evenness': color_evenness,
            'smoothness': smoothness,
            'cleanliness': cleanliness
        }

    def _analyze_skin_cleanliness(self, face_img):
        """–ê–Ω–∞–ª–∏–∑ —á–∏—Å—Ç–æ—Ç—ã –∫–æ–∂–∏"""
        hsv = cv2.cvtColor(face_img, cv2.COLOR_RGB2HSV)
        
        lower_red1 = np.array([0, 50, 50])
        upper_red1 = np.array([10, 255, 255])
        lower_red2 = np.array([170, 50, 50])
        upper_red2 = np.array([180, 255, 255])
        
        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
        red_mask = mask1 + mask2
        
        red_ratio = np.sum(red_mask > 0) / red_mask.size
        
        return max(0, 1 - red_ratio * 3)

    def _analyze_stress(self, face_img, mesh_results, emotion_analysis):
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–µ—Å—Å–∞"""
        brow_tension = 0.3
        mouth_tension = 0.4
        
        base_stress_score = 100 - (brow_tension * 40 + mouth_tension * 35)
        
        if emotion_analysis:
            emotion_stress = emotion_analysis.get('computed_stress', base_stress_score)
            combined_stress = (base_stress_score * 0.7 + emotion_stress * 0.3)
            base_stress_score = max(0, min(combined_stress, 100))
        
        return {
            'score': base_stress_score,
            'brow_tension': brow_tension,
            'mouth_tension': mouth_tension
        }

    def _analyze_emotions(self, img_rgb):
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π —á–µ—Ä–µ–∑ Hugging Face"""
        try:
            from PIL import Image
            pil_img = Image.fromarray(img_rgb)
            emotion_results = self.emotion_detector(pil_img)
            
            stress_indicators = ['sad', 'angry', 'fear', 'disgust']
            stress_score = 0
            for result in emotion_results:
                if result['label'].lower() in stress_indicators:
                    stress_score += result['score']
            
            return {
                'emotions': emotion_results,
                'computed_stress': min(stress_score * 100, 100),
                'dominant_emotion': emotion_results[0]['label'] if emotion_results else 'neutral'
            }
        except Exception as e:
            print(f"Emotion analysis failed: {e}")
            return {}

    def _calculate_scores(self, front_data, left_data, right_data):
        """–†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö —Å–∫–æ—Ä–æ–≤"""
        energy_score = front_data['energy']['score']
        skin_score = front_data['skin']['score']
        stress_score = front_data['stress']['score']
        
        aura_score = (energy_score * 0.4 + skin_score * 0.35 + stress_score * 0.25)
        
        return {
            'aura_score': round(aura_score, 1),
            'energy_score': round(energy_score, 1),
            'skin_score': round(skin_score, 1),
            'stress_score': round(stress_score, 1)
        }

    def _compile_metrics(self, front_data):
        """–ö–æ–º–ø–∏–ª—è—Ü–∏—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫"""
        return {
            'dark_circles': front_data['energy']['dark_circles'],
            'eye_freshness': front_data['energy']['eye_freshness'],
            'skin_smoothness': front_data['skin']['smoothness'],
            'skin_evenness': front_data['skin']['evenness'],
            'skin_cleanliness': front_data['skin']['cleanliness']
        }

    def _generate_recommendations(self, scores, metrics):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        if metrics['dark_circles'] > 0.1:
            confidence = min(metrics['dark_circles'] * 5, 1.0)
            priority = 'high' if metrics['dark_circles'] > 0.2 else 'medium'
            recommendations.append({
                'category': 'energy',
                'priority': priority,
                'message': '–¢–µ–º–Ω—ã–µ –∫—Ä—É–≥–∏ –ø–æ–¥ –≥–ª–∞–∑–∞–º–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: —Å–æ–Ω 7-8 —á–∞—Å–æ–≤, —Ö–æ–ª–æ–¥–Ω—ã–µ –∫–æ–º–ø—Ä–µ—Å—Å—ã',
                'action': 'improve_sleep',
                'confidence': round(confidence, 2)
            })
        
        if scores['skin_score'] < 60:
            recommendations.append({
                'category': 'skin',
                'priority': 'high' if scores['skin_score'] < 40 else 'medium',
                'message': '–ö–æ–∂–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Ö–æ–¥. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —É–≤–ª–∞–∂–Ω—è—é—â–∏–µ —Å—Ä–µ–¥—Å—Ç–≤–∞',
                'action': 'skin_hydration',
                'confidence': round(1 - (scores['skin_score'] / 100), 2)
            })
        
        if scores['stress_score'] < 70:
            recommendations.append({
                'category': 'stress',
                'priority': 'medium',
                'message': '–ü–æ–≤—ã—à–µ–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—ã—Ö–∞—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏',
                'action': 'stress_management',
                'confidence': round(1 - (scores['stress_score'] / 100), 2)
            })
        
        recommendations.sort(key=lambda x: (x['priority'] == 'high', x['confidence']), reverse=True)
        return recommendations

    def get_celebrity_match(self, user_scan):
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–µ–π –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–∏"""
        if not self.celebrity_database:
            return {"error": "–ë–∞–∑–∞ –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–µ–π –ø—É—Å—Ç–∞"}
        
        best_match = None
        best_similarity = 0
        
        for celeb_name, celeb_data in self.celebrity_database.items():
            similarity = self._calculate_similarity(user_scan, celeb_data)
            
            if similarity > best_similarity:
                best_similarity = similarity
                best_match = celeb_data
        
        if best_match and best_similarity > 0.4:
            return {
                "celebrity": best_match["name"],
                "similarity_percent": round(best_similarity * 100, 1),
                "verdict": f"–í—ã –ø–æ—Ö–æ–∂–∏ –Ω–∞ {best_match['name']} –Ω–∞ {round(best_similarity * 100, 1)}%!"
            }
        else:
            return {
                "celebrity": None,
                "verdict": "–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å! –í—ã –æ—Å–æ–±–µ–Ω–Ω—ã–µ! ‚ú®"
            }

    def _calculate_similarity(self, user_scan, celeb_data):
        """–†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º"""
        user_metrics = user_scan["metrics"]
        celeb_metrics = celeb_data["metrics"]
        
        total_similarity = 0
        metric_count = 0
        
        for metric, celeb_value in celeb_metrics.items():
            user_value = user_metrics.get(metric, 0)
            similarity = 1 - abs(user_value - celeb_value)
            total_similarity += max(0, similarity)
            metric_count += 1
        
        return total_similarity / metric_count if metric_count > 0 else 0

    def _generate_scan_id(self):
        timestamp = str(time.time())
        return f"scan_{hashlib.md5(timestamp.encode()).hexdigest()[:8]}"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ç–∫–µ–Ω–¥–∞
def analyze_3_images(front_bytes: bytes, left_bytes: bytes, right_bytes: bytes) -> dict:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ 3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    analyzer = AuraHealthAnalyzer(use_huggingface=True)
    return analyzer.analyze_3d_scan_from_bytes(front_bytes, left_bytes, right_bytes)